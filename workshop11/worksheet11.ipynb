{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90051 Workshop 11\n",
    "## Bayesian Regression\n",
    "***\n",
    "In this workshop we'll look at Bayesian regression. Briefly, this involves learning a linear regression model from a training set of $(\\mathbf{x}, y)$ pairs, where $\\mathbf{x}$ is a feature vector and $y$ is a real-valued response variable. Earlier we looked at ridge regression, which involved:\n",
    "1. assuming a linear relationship between inputs and outputs, i.e., $y \\approx \\mathbf{w} \\cdot \\mathbf{x}$ for all pairs\n",
    "2. minimising the *residual sum of squares error*, that is finding the parameters $\\hat{\\mathbf{w}}$ that give the best fit to the training responses (with a regularisation term that penalises large weights) \n",
    "3. using $\\hat{\\mathbf{w}}$ to make test inferences\n",
    "\n",
    "We'll now look at *Bayesian* inference for the above model. \n",
    "In this case we don't follow steps 2 and 3 above, but rather formulate the *posterior* over the weights, and make test inferences using *all settings of the weights* according to their posterior probability. \n",
    "These operations can be solved exactly, using linear algebra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Regression data set\n",
    "Let's generate a small synthetic data set in 1D according to the following model:\n",
    "$$\n",
    "\\newcommand\\ys{\\mathbf{y}}\n",
    "\\newcommand\\xs{\\mathbf{x}}\n",
    "\\newcommand\\Xs{\\mathbf{X}}\n",
    "\\newcommand\\ws{\\mathbf{w}}\n",
    "\\newcommand\\Vs{\\mathbf{V}}\n",
    "\\newcommand\\Is{\\mathbf{I}}\n",
    "\\begin{align*}\n",
    "x &\\sim \\mathrm{Uniform}[0,1] \\\\\n",
    "y|x, \\sigma^2 &\\sim \\mathrm{Normal}\\!\\left[5\\left(x - \\frac{1}{2}\\right)^2, \\sigma^2 \\right]\n",
    "\\end{align*}\n",
    "$$\n",
    "By focussing on the 1D case, it'll be straightforward to visualise the results.\n",
    "We'll keep the data set small, since Bayesian approaches are particularly useful when limited data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_instances = 8\n",
    "sigma = 0.1 # keep this small: don't want too much noise\n",
    "\n",
    "# generate data matrix with rows as instances\n",
    "X = np.random.uniform(size=(n_instances,1))\n",
    "\n",
    "# generate the target response values using the quadratic function\n",
    "# and additive noise\n",
    "Y = np.random.normal(loc=5*(X - 0.5)**2, scale=sigma, size=(n_instances,1)).ravel()\n",
    "\n",
    "# plot the training data\n",
    "plt.plot(X, Y, 'ro', label='Train')\n",
    "\n",
    "# and plot the true function (without noise)\n",
    "X_test = np.linspace(-0.2, 1.2, 100)\n",
    "X_test = X_test[:,np.newaxis]\n",
    "Y_test_gold = 5*(X_test - 0.5)**2 \n",
    "plt.plot(X_test, Y_test_gold, 'k', label='Gold')\n",
    "plt.legend()\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial basis functions\n",
    "Since the relationship between $y$ and $x$ is non-linear, we'll apply polynomial basis expansion to degree $d$.\n",
    "Specifically, we replace the original data matrix $\\mathbf{X}$ by the transformed matrix below:\n",
    "$$\n",
    "\\mathbf{\\Phi} = \\begin{bmatrix}\n",
    "    1 & x_1 & x_1^2 & \\ldots & x_1^d \\\\\n",
    "    1 & x_2 & x_2^2 & \\ldots & x_2^d \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    1 & x_n & x_n^2 & \\ldots & x_n^d \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Note that we're including a column of ones to account for the bias term.\n",
    "\n",
    "The function below is a wrapper around `sklearn.preprocessing.PolynomialFeatures`, which implements the above transformation on a train/test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_features(X_train, X_test, degree, include_bias=True):\n",
    "    \"\"\"\n",
    "    Augments data matrices X_train and X_test with polynomial features\n",
    "    \"\"\"\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=include_bias)\n",
    "    \n",
    "    Phi_train = poly.fit_transform(X_train)\n",
    "    Phi_test = poly.fit_transform(X_test)\n",
    "    \n",
    "    return Phi_train, Phi_test\n",
    "    \n",
    "Phi, Phi_test = polynomial_features(X, X_test, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**: How does this basis trick relate to kernel methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bayesian regression with known variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we're going to implement the Bayesian regression model described in lectures.\n",
    "\n",
    "Let's being with a quick recap. The model assumes the data is generated according to a Normal distribution, where the mean is a linear function of the input vector and the variance $\\sigma^2$ is **assumed known**.\n",
    "The prior over the weight vector $\\ws$ is also Normalâ€”by setting the mean to zero and choosing a small $\\gamma^2$, weights with large magnitude are penalised.\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\ws | \\gamma &\\sim \\mathrm{Normal}\\!\\left[\\mathbf{0}, \\gamma^2 \\mathbf{I}_m\\right] & \\mbox{Prior} \\\\\n",
    "y | \\mathbf{x}, \\mathbf{w}, \\sigma &\\sim \\mathrm{Normal}\\!\\left[\\xs^\\intercal \\ws, \\sigma^2\\right] & \\mbox{Likelihood}\n",
    "\\end{align*}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this formulation, the next step is to solve for the posterior over $\\ws$\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(\\ws | \\Xs, \\ys, \\sigma, \\gamma) = \\frac{p(\\ys | \\Xs, \\ws, \\sigma) p(\\ws | \\gamma)}{p(\\ys | \\Xs, \\sigma)}\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\Xs \\in \\mathbb{R}^{n \\times m}$ is the feature matrix and $\\ys \\in \\mathbb{R}^{n}$ is the vector of target values for each instance.\n",
    "\n",
    "In lectures, we derived the following solution:\n",
    "$$\n",
    "\\ws | \\Xs, \\ys, \\sigma, \\gamma \\sim  \\textrm{Normal}(\\ws_N, \\mathbf{V}_N)\n",
    "$$\n",
    "where $\\Vs_N = \\sigma^2 \\left( \\Xs^\\intercal \\Xs + \\frac{\\sigma^2}{\\gamma^2} \\Is_m \\right)^{-1}$ and $\\ws_N = \\frac{1}{\\sigma^2} \\Vs_N \\Xs^\\intercal \\ys$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the posterior parameters\n",
    "Complete the function below to compute the posterior mean $\\mathbf{w}_N$ and covariance matrix $\\mathbf{V}_N$ for the weights based on the expression above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_posterior_params(X, Y, sigma, gamma):\n",
    "    \"\"\"\n",
    "    Compute the parameters (mean and covariance) for the posterior over the weights\n",
    "    \n",
    "    Arguments\n",
    "    =========\n",
    "    X : numpy array, shape: (n_instances, n_features)\n",
    "        feature matrix\n",
    "    Y : numpy array, shape: (n_instances,)\n",
    "        target class labels relative to X\n",
    "    sigma : float\n",
    "        positive scale parameter for y\n",
    "    gamma : float\n",
    "        positive scale parameter for w_i\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    The following items in a tuple:\n",
    "    w_N : numpy array, shape: (n_features,)\n",
    "        mean parameter\n",
    "    V_N : numpy array, shape: (n_features, n_features)\n",
    "        covariance parameter\n",
    "    \"\"\"\n",
    "    V_N = ... # fill in\n",
    "    w_N = ... # fill in\n",
    "    \n",
    "    return w_N, V_N\n",
    "\n",
    "gamma = 10 # larger implies more permissive, i.e. a more diffuse prior\n",
    "w_N, V_N = compute_posterior_params(Phi, Y, sigma, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the prior and posterior over $\\mathbf{w}$ to see how they differ. \n",
    "Since $\\mathbf{w}$ is $d+1$-dimensional, we can only visualise the posterior over a couple of the weights.\n",
    "Here we look at $p(w_1, w_2|\\mathbf{X}, \\mathbf{y}, \\sigma, \\gamma)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a 2d plot mesh\n",
    "w1, w2 = np.mgrid[-10:10:.05, -10:10:.05]\n",
    "grid = np.c_[w1.ravel(), w2.ravel()]\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "# plot a bivariate normal for the prior\n",
    "ax = fig.add_subplot(121)\n",
    "p_w = sp.stats.multivariate_normal.pdf(grid, mean=np.zeros(2), cov=gamma**2 * np.identity(2))\n",
    "CS = ax.contour(w1, w2, p_w.reshape(w1.shape))\n",
    "plt.clabel(CS, inline=1, fontsize=10)\n",
    "ax.plot(0, 0, 'rx') # add prior mean\n",
    "plt.xlabel('$w_1$')\n",
    "plt.ylabel('$w_2$')\n",
    "plt.title('Prior $p(w_1, w_2|\\gamma)$')\n",
    "\n",
    "# plot a bivariate normal for the posterior\n",
    "ax = fig.add_subplot(122)\n",
    "p_w = sp.stats.multivariate_normal.pdf(grid, mean=w_N[1:3], cov=V_N[1:3,1:3])\n",
    "CS = ax.contour(w1, w2, p_w.reshape(w1.shape))\n",
    "plt.clabel(CS, inline=1, fontsize=10)\n",
    "ax.plot(w_N[1], w_N[2], 'rx') # add posterior mean\n",
    "plt.xlabel('$w_1$')\n",
    "plt.ylabel('$w_2$')\n",
    "plt.title('Posterior $p(w_1, w_2|X,y,\\gamma,\\sigma)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion question**: Can you explain why the prior and the posterior are so different? How is this related to the dataset? Why are the ellipses in the posterior not aligned to the axes? *You might want to change the parameter indices from 0,1 to other pairs to get a better idea of the full posterior.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian inference\n",
    "One way of doing inference for $y|\\mathbf{x}$ is to draw a sample of weight vectors from the posterior (sampling from a Gaussian). \n",
    "\n",
    "Complete the function below to compute the predictive mean $E[y|\\mathbf{x}] = \\mathbf{w} \\cdot \\mathbf{x}$. \n",
    "Then run the code block below to plot 50 samples from the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_mean(X, w):\n",
    "    \"\"\"\n",
    "    Compute the predictive mean for the target variable, given X and w\n",
    "    \n",
    "    Arguments\n",
    "    =========\n",
    "    X : numpy array, shape: (n_instances, n_features)\n",
    "        feature matrix\n",
    "    w : numpy array, shape: (n_features,)\n",
    "        weights vector\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    Y_mean : numpy array, shape: (n_instances,)\n",
    "        predictive mean for each instance in X\n",
    "    \"\"\"\n",
    "    # your code here #\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some samples from the posterior\n",
    "for i in range(50):\n",
    "    # draw a weight vector\n",
    "    w_i = np.random.multivariate_normal(w_N, V_N, 1).ravel()\n",
    "    # plot the predictions for this weight vector\n",
    "    p = plt.plot(X_test.ravel(), target_mean(Phi_test, w_i), ':', lw=1)\n",
    "\n",
    "plt.plot(X, Y, 'ro', label='Train')\n",
    "plt.plot(X_test, target_mean(Phi_test, w_N), 'g:', label='Mean')\n",
    "plt.plot(X_test.ravel(), Y_test_gold, 'k', label='Gold')\n",
    "\n",
    "plt.ylim(-2,5)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting to see what happens near the training data points, and away from them, in particular the edges of the plot.\n",
    "We'll come back to this.\n",
    "\n",
    "But there's a more elegant solution, as the predictive distribution can be found in closed form. Namely\n",
    "$$\n",
    "\\begin{align*}\n",
    "y_{*} | \\xs_{*}, \\ws_N, \\Vs_N, \\sigma &= \\mathrm{Normal}\\!\\left[\\xs_{*}'\\ws_N, \\sigma^2_N(\\xs_{*})\\right] \\\\\n",
    "\\sigma^2_N(\\xs_{*}) & = \\sigma^2 + \\xs_{*}' \\Vs_N \\xs_{*}\n",
    "\\end{align*}\n",
    "$$\n",
    "Note that the predictive mean is a simple application of the posterior mean to the data point, but the predictive variance is a bit more complicated. \n",
    "\n",
    "Complete the function below to evaluate the predictive standard deviation, i.e. $\\sigma_N(\\mathbf{x}_{*})$. \n",
    "Then run the following code block to plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_std(X, V_N, sigma):\n",
    "    \"\"\"\n",
    "    Compute the predictive standard deviation for the target variable, given X, V_N and sigma\n",
    "    \n",
    "    Arguments\n",
    "    =========\n",
    "    X : numpy array, shape: (n_instances, n_features)\n",
    "        feature matrix\n",
    "    V_N : numpy array, shape: (n_features, n_features)\n",
    "        covariance parameter\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    std : numpy array, shape: (n_instances,)\n",
    "        predictive standard deviation for each instance in X\n",
    "    \"\"\"\n",
    "    # your code here #\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the standard deviation using the formula above\n",
    "Y_test_mean = target_mean(Phi_test, w_N)\n",
    "Y_test_std = target_std(Phi_test, V_N, sigma)\n",
    "\n",
    "plt.plot(X, Y, 'ro', label='Train')\n",
    "plt.fill_between(X_test.ravel(), Y_test_mean + 2*Y_test_std, Y_test_mean - 2*Y_test_std, alpha=0.1, label='95% CI')\n",
    "plt.plot(X_test.ravel(), Y_test_mean, 'g:', label='Mean')\n",
    "plt.plot(X_test.ravel(), Y_test_gold, 'k', label='Gold')\n",
    "\n",
    "plt.ylim(-2,5)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**: How does the uncertainty plot compare to the samples above? How does the uncertainty change relative to the distance from training points? Can you explain why?\n",
    "\n",
    "**Practical**: How does the setting of `gamma` affect the fit? How about the number of instances in the training set? Try some other values and see what happens.\n",
    "\n",
    "**Discussion**: Is a 9th order polynomial a good choice for this problem? Based on the results above, would you recommend this model, or make a different choice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bayesian model selection\n",
    "In this section, we'll revisit the assumption of having a 9th order polynomial. \n",
    "The evidence gives us a good way of evaluating the quality of fit.\n",
    "\n",
    "Note that the evidence (a.k.a. marginal likelihood) is given by:\n",
    "$$\n",
    "p(\\ys|\\Xs, \\sigma, \\gamma) = \\int p(\\ys | \\Xs, \\sigma, \\gamma, \\ws) p(\\ws) d \\ws\n",
    "$$\n",
    "i.e. it's the likelihood function over the space of models for which the parameters $\\ws$ have been marginalised out (see Sec 3.4 of Bishop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(w, X, Y, sigma, gamma):\n",
    "    n_instances, n_features = X.shape\n",
    "    alpha, beta = 1/float(gamma**2), 1/float(sigma**2)\n",
    "    rss = np.sum((Y - np.dot(X, w))**2)\n",
    "    wpen = np.dot(w, w)\n",
    "    E = beta/2.0 * rss + alpha/2.0 * wpen\n",
    "    A = alpha * np.identity(n_features) + beta * X.T @ X\n",
    "    lE = n_features/2.0 * np.log(alpha) + n_instances/2.0 * np.log(beta) - E \\\n",
    "        - 0.5 * np.log(np.linalg.det(A)) - n_instances/2.0 * np.log(2.0 * np.pi)\n",
    "    # return both the evidence, and the RSS term (the raw quality of fit)\n",
    "    return {'logEvidence': lE, 'RSS': rss}\n",
    "\n",
    "# what's the evidence for our 9th order model?\n",
    "evaluate(w_N, Phi, Y, sigma, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what happens if we use a lower order model, e.g., a 3rd order model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_3, Phi_3_test = polynomial_features(X, X_test, 3)\n",
    "\n",
    "w_N_3, V_N_3 = compute_posterior_params(Phi_3, Y, sigma, gamma)\n",
    "Y_test = target_mean(Phi_3_test, w_N_3)\n",
    "Y_test_std = target_std(Phi_3_test, V_N_3, sigma)\n",
    "    \n",
    "plt.plot(X, Y, 'ro', label='Train')\n",
    "plt.fill_between(X_test.ravel(), Y_test_mean + 2*Y_test_std, Y_test_mean - 2*Y_test_std, alpha=0.1, label='95% CI')\n",
    "plt.plot(X_test.ravel(), Y_test_mean, 'g:', label='Mean')\n",
    "plt.plot(X_test.ravel(), Y_test_gold, 'k', label='Gold')\n",
    "\n",
    "plt.ylim(-2,5)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**: Does that look like a better fit to you? Consider both the interval $[0,1]$ near the training points, and those outside this range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the *evidence* says, and compare this to the above result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(w_N_3, Phi_3, Y, sigma, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RSS has barely changed, but the evidence is much higher. We can look at various model orders to see which has the best *evidence* to perform Bayesian model selection: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_range = np.arange(1, 11)\n",
    "logEvidence = []\n",
    "RSS = []\n",
    "for d in d_range:\n",
    "    Phi_d, Phi_d_test = polynomial_features(X, X_test, d)\n",
    "    w_N_d, V_N_d = compute_posterior_params(Phi_d, Y, sigma, gamma)\n",
    "    result = evaluate(w_N_d, Phi_d, Y, sigma, gamma)\n",
    "    print('Degree {}. Log evidence {}. RSS {}.'.format(d, result['logEvidence'], result['RSS']))\n",
    "    logEvidence.append(result['logEvidence'])\n",
    "    RSS.append(result['RSS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the above log evidence values against the model order\n",
    "ax1 = plt.subplot(211)\n",
    "ax1.plot(d_range, logEvidence)\n",
    "plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "plt.ylabel('Log Evidence')\n",
    "\n",
    "ax2 = plt.subplot(212, sharex=ax1)\n",
    "ax2.plot(d_range, RSS)\n",
    "plt.xlabel('Polynomial degree')\n",
    "plt.ylabel('RSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**: So which model class will be chosen? Is this a reasonable situation? \n",
    "\n",
    "**Practical**: Rerun the code with a new random training set, or different values of *N*, such as 2 or 3 points or 20; the results may be different. Can you explain why the outcome might be different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Bayesian regression with unknown variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real settings, the variance for $y$, $\\sigma^2$ is unknown.\n",
    "It's possible to account for this by putting the following prior on $\\sigma^{2}$:\n",
    "$$\n",
    "\\sigma^{-2} \\sim \\textrm{Gamma}(\\alpha_1, \\alpha_2)\n",
    "$$\n",
    "where $\\alpha_1, \\alpha_2 > 0$ are hyperparameters.\n",
    "\n",
    "We can also put a prior over the variance for the weights, $\\gamma^2$:\n",
    "$$\n",
    "\\gamma^{-2} \\sim \\textrm{Gamma}(\\lambda_1, \\lambda_2)\n",
    "$$\n",
    "where $\\lambda_1, \\lambda_2 > 0$ are hyperparameters.\n",
    "\n",
    "This model for regression (with the additional priors over $\\gamma$ and $\\sigma$) is implemented in `sklearn.linear_models.BayesianRidge`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Apply `BayesianRidge` to the training data (with the polynomial basis expansion) and compare the results to our simpler model.\n",
    "What happens if the value of $\\sigma$ used in our model deviates from the true value used to generate the data?\n",
    "Is `BayesianRidge` more robust in this case?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
